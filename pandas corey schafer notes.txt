

import pandas as pd

df = pd.read_csv('')


df.shape   # shape attribute gives us the number of rows and column in a tuple form  (88883, 85)


df.info()  # info method will give us the number of rows and columns and also all of the data types of all columns 


set_option() # Sets the value of the specified option.  for more info --> https://pandas.pydata.org/docs/reference/api/pandas.set_option.html

pd.set_option('display.max_columns', 85)
pd.set_option('display.max_rows', 85)

Remember that we are setting it for pd, which means it will be appied to all the dataframes


df.head(7) # Gives us first 7 rows. Default is 5, if you didn't pass anything \
df.tail(7) # Gives us last 7 rows. 

check for negative indexing with head and tail





Say for example, what if doesn't exist:

person = {
    "first": "Corey", 
    "last": "Schafer", 
    "email": "CoreyMSchafer@gmail.com"
}


people = {
    "first": ["Corey"], 
    "last": ["Schafer"], 
    "email": ["CoreyMSchafer@gmail.com"]
}

# making all our values in our dictionaries as a list 
# first value of the list is our first person, second value will be our second person and third value is third person and so on. 
# the keys are columns and the values are the rows 

people = {
    "first": ["Corey", 'Jane', 'John'], 
    "last": ["Schafer", 'Doe', 'Doe'], 
    "email": ["CoreyMSchafer@gmail.com", 'JaneDoe@email.com', 'JohnDoe@email.com']
}



If you want to see the 'email' column, then you can simply, 
people['email'] # ["CoreyMSchafer@gmail.com", 'JaneDoe@email.com', 'JohnDoe@email.com']

# So Dataframe are very similar to this, but with more functionality than what we have here in standard python 



df = pf.DataFrame(people) # converting dictionary into dataframe 
df 

#
     first	last	        email
0	Corey	Schafer	        CoreyMSchafer@gmail.com
1	Jane	Doe	            JaneDoe@email.com
2	John	Doe	            JohnDoe@email.com


# Here 0, 1, 2 are indexes 
# to access a single columns is similar to how we access the key in dictionary -->  df['first'] df['last']  df['email']  
# remember when accessing a single column, it will return a series,  which means type(df['first']) --> pandas.core.series.Series

A series is still basically a list of data but just like with a dataframe, it has a lot more functionality than just a list 
In online, it might be one dimensional data, but in layman's terms, it's just a rows of data

So,

Dataframe - rows and columns
Series - row of single column 


Dataframe basically contains, is a container for multiple series objects. So we can say the email column is a series, last columns is a series 



df['email'] is same as df.email

prefer to use bracket notation instead of dot notation 

reasons: one of columns might be in same name as the attribute or methods of a dataframe   


 
 
to access multiple columns: 
---------------------------
df[['lastname', 'email']]  #passing a list of column names 

Also remember, when retrieving multiple columns, when don't get series, we get another dataframe


df.columns # to see the columns 
#
Index(['first', 'last', 'email'], dtype='object')





to access rows:
---------------

we use loc and iloc to get rows

iloc allows us to access rows by integer location

df.iloc[0] # gives us the first row, returns a series that contains the values of the first row of data 

#
first           Corey
last           Schafer
email     CoreyMSchafer@gmail
Name: 0, dtype: object 


Note that: Earlier when we access columns, the index will be 0,1,2.. and so on. But when we access rows, the index will the name of the column

Just like we select multiple columns, we can also select multiple rows by passing in a list of integers


df.iloc[[0, 1]] # gets us the first two row of data, note that the return type is a dataframe

you can also select the columns alone to display, by passing in a second value to 'iloc' indexing:

first argument: rows
second argument: column 

df.iloc[[0, 1], 2]  # gives us the email column
#
0    CoreyMSchafer@gmail.com
1          JaneDoe@email.com
Name: email, dtype: object

with 'iloc', we were searching by its integer location, and with 'loc', we're going to search by its labels

Labels for rows will be its indexes. And again we don't have custom indexes right now. So, the index is just a default range of integers. 


df
#
    first	last	        email
0	Corey	Schafer	        CoreyMSchafer@gmail.com
1	Jane	Doe	            JaneDoe@email.com
2	John	Doe	            JohnDoe@email.com



df.loc[0]

# gets the row with the label 0
#
first           Corey
last           Schafer
email     CoreyMSchafer@gmail
Name: 0, dtype: object 



df.loc[[0, 1], 'email'] # gets us email column of first row and second row # returns series
#	            
0	CoreyMSchafer@gmail.com	   
1	JaneDoe@email.com
Name: email, dtype: object



df.loc[[0, 1], ['email', 'last']]  # gets us the email and last column of first row and second row  # returns dataframe


           email	            last
0	CoreyMSchafer@gmail.com	   Schafer
1	JaneDoe@email.com	       Doe



df[0,'Hobbyist']  # returns the Hobbyist column of the first record or first row
# Yes


df[[0, 1, 2], 'Hobbyist']  # returns the Hobbyist columns of first three rows

#
0  Yes
1  No
2  Yes
Name: Hobbyist dtype: object



we can also use slicing to grab multiple rows and columns: 

Note: the last value is inclusive, whereas in the normal slicing doesn't
The reason they made it inclusive is, when you see that we mentioned 'Employment' below, say if the last value wasn't inclusive, then we have to go back everytime and check the column name thats need to be given next to column that we actually needs 

df.loc[0:2, 'Hobbyist':'Employment']   # from column hobbyist to employment  and from 0th row to 2nd row

    Hobbyist	OpenSourcer                    	OpenSource	                                     Employment
	
0	Yes	         Never	                    The quality of OSS and closed source software ...	Not employed, and not looking for work
1	No	         Less than once per year	The quality of OSS and closed source software ...	Not employed, but looking for work
2	Yes	         Never	                    The quality of OSS and closed source software ...	Employed full-time


 
df.['Hobbyist'].value_counts()

Yes     71257
No      17626

Name: Hobbyist   dtype:int64



======================================================================================================================================================================================

Indexes: 
========
to set custom index: 
---------------------
df.set_index('email', inplace=True)   # when inplace=True, changes are reflected in the original dataframe

#

	                       first	last
email		
CoreyMSchafer@gmail.com	   Corey	Schafer
JaneDoe@email.com	       Jane	    Doe
JohnDoe@email.com	       John	    Doe


to specifically look at the index: 

df.index
#
Index(['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JohnDoe@email.com'], dtype='object', name='email')




df.loc['CoreyMSchafer@gmail.com', 'last']
#
'Schafer'


df.loc[0] will give you error at this point, because both the row and column index has labels and not integers. But if you still want to use integer indexing, you can use 'iloc'




df.reset_index(inplace=True)  #resets the index to its old form

df
#
     email	                    first	last
0	CoreyMSchafer@gmail.com	    Corey	Schafer
1	JaneDoe@email.com	        Jane	Doe
2	JohnDoe@email.com	        John	Doe



to set the index while the reading the file:

df = pd.read_csv('data/survey_results_public.csv', index_col='Respondent')
schema_df = pd.read_csv('data/survey_results_schema.csv', index_col='Column')


schema_df.loc['MgrIdiot', 'QuestionText']    # Note that here 'MgrIdiot' is a row and 'QuestionText' is a column
#
'How confident are you that your manager knows what theyâ€™re doing?


schema_df.sort_index(inplace=True)  # sorts the index column based on alphabetical order
schema_df.sort_index(ascending=False) # to sort it in descending order


======================================================================================================================================================================================

Filtering:
===========

people = {
    "first": ["Corey", 'Jane', 'John'], 
    "last": ["Schafer", 'Doe', 'Doe'], 
    "email": ["CoreyMSchafer@gmail.com", 'JaneDoe@email.com', 'JohnDoe@email.com']
}


import pandas as pd
df = pd.DataFrame(people)


df
#
    first	last	    email
0	Corey	Schafer	    CoreyMSchafer@gmail.com
1	Jane	Doe	        JaneDoe@email.com
2	John	Doe	        JohnDoe@email.com



df['last'] == 'Doe'
#
0    False
1    True
2    True
Name: last, dtype: bool




filt = (df['last'] == 'Doe')

df[filt]
#
    first	last	    email
1	Jane	Doe	        JaneDoe@email.com
2	John	Doe	        JohnDoe@email.com


or 

df[df['last'] == 'Doe']
#
    first	last	    email
1	Jane	Doe	        JaneDoe@email.com
2	John	Doe	        JohnDoe@email.com




We can also use df.loc and this is what I prefer:

df.loc[filt]
#
    first	last	    email
1	Jane	Doe	        JaneDoe@email.com
2	John	Doe	        JohnDoe@email.com


So, this is one reason why pandas can be a bit confusing to people because there are multiple things that you can pass into these different brackets to get different results. So, what we have seen before is that df.loc() is used to look up rows and columns by label. But, if you pass in a series of Booleans like we did before, then you can also filter data out.

Now the reason that I like using loc is because we can still grab the specific columns that we want as well. Say for example, if we want the email column, then I could simply pass in a second value to the loc function,

df.loc[filt, 'email']

#
1   JaneDoe@email
2   JohnDoe@email
Name: email, dtype: object

Now when you remember, the first value to loc function are the rows and the second value here are the columns. 
Here filt are the records that we want and we want email column which is being passed as a second argument





Now we can't use the Python built-in AND OR keywords for our filters, so we're going to be using some other symbols, we going to use 
'&'(ampersand)  - And
| - OR
'~' - NOT
Example:
filt = (df['last'] == 'Doe') & (df['first'] == 'John')

df.loc[filt, 'email']
#
2   JohnDoe@email
Name: email, dtype: object



filt = (df['last'] == 'Schafer') | (df['first'] == 'John')

df.loc[filt, 'email']
#
0     CoreyMSchafer@gmail
2     JohnDoe@email
Name: email, dtype: object



df.loc[~filt, 'email']
#
1    JaneDoe@email.com
Name: email, dtype: object


Some more examples: 
-------------------

high_salary = (df['ConvertedComp'] > 70000)

df.loc[high_salary]


Now, inorder to narrow these further, say we want some selected columns, we can pass those columns as list as the second argument.

df.loc[high_salary, ['Country', 'LanguageWorkedWith', 'ConvertedComp']]


countries = ['United States', 'India', 'United Kingdom', 'Germany', 'Canada']
filt = df['Country'].isin(countries)
df.loc[filt, 'Country']

#
Respondent
1            United Kingdom
4            United States
....



We can also do some string operations:(More string operations are there, learn it in google) 

Let's say we want to filter people who knows python,

filt = df['LanguageWorkedWith'].str.contains('Python', na=False) # na=False means, its not going to do anything with NaN values 
 
filt
#
Respondent
1         True
2         True
3        False
4         True
5         True
         ...  
88377    False
88601    False
88802    False
88816    False
88863    False
Name: LanguageWorkedWith, Length: 88883, dtype: bool

df.loc[filt, 'LanguageWorkedWith'] 



======================================================================================================================================================================================

Updating Rows and Columns (Alter existing rows and columns):
------------------------------------------------------------

people = {
    "first": ["Corey", 'Jane', 'John'], 
    "last": ["Schafer", 'Doe', 'Doe'], 
    "email": ["CoreyMSchafer@gmail.com", 'JaneDoe@email.com', 'JohnDoe@email.com']
}


import pandas as pd

df = pd.DataFrame(people)

df
#
    first	last	       email
0	Corey	Schafer	       CoreyMSchafer@gmail.com
1	Jane	Doe	           JaneDoe@email.com
2	John	Doe	           JohnDoe@email.com


for updating columns:
---------------------

df.columns
#
Index(['first', 'last', 'email'], dtype='object')


df.columns = ['first_name', 'last_name', 'email']  # to change all the columns 

df.columns = [x.lower() for x in df.columns]  # if you want to do specific thing in all your column names, you can simply use list comprehension

df.columns = df.columns.str.replace(' ', '_')  # Say if you want to replace '_' with a space

df.rename(columns={'first_name': 'first', 'last_name': 'last'}, inplace=True)  # if you want to change specific column names



Updating data in our rows:
--------------------------

df.loc[2]  --> will get the specific row and now we can update this row in many rows, we can pass in list of all the new values 

df.loc[2] = ['John', 'Smith', 'JohnSmith@email.com']

Note: you can also conditionals, to get the row that you want to change




you can also specify the exact columns that you want to change:
df.loc[2, ['last', 'email']] = ['Doe', 'JohnDoe@email.com']

df.loc[2, 'last'] = 'Smith'  # to change a single value

we can also use 'at' to change a single value: 
df.at[2, 'last'] = 'Doe'

And I'll be honest here, I'll have to look at the documentation of why we would use 'at' instead of 'loc' when we only need to get or set a single value. Maybe it's for performance reasons. 
But I personally find myself using 'loc' even for single values. I actually did look it up in the Pandas documentation, but all it says that 'at' is similar to 'loc'. 




Okay, so now let me show you one mistake that is very common, and that is when people try to change a value without using one of these indexes without using 'loc' or 'at'. So let me show you what this error or this warning would look like. 


filt = (df['email'] == 'JohnDoe@email.com')
df[filt]['last'] = 'Smith'

/Users/coreyschafer/tutorial_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  
  
Essentially it's because the way that we're doing it here requires multiple operations in the background which can determine whether Pandas returns a view or a copy of our data frame. So, when our value isn't getting set it's because it's getting set on a temporary object that's just getting tossed out immediately after. So, Pandas does a lot better job of explaining this specific warning and they have a link. So if you want to learn more about this then you can just click on that warning or go to this link and it explains it in a lot more detail. 

But the moral of the story here is that when you're setting values, just use 'loc' or the 'at' indexes that we've already seen and you shouldn't have any problems. 


So, doing the same operation using 'loc':
filt = (df['email'] == 'JohnDoe@email.com')
df.loc[filt, 'last'] = 'Smith'




To apply multiple rows:
-----------------------


df['email'] = df['email'].str.lower() # to change all the row of the email column to lower case



lets look at the famous update methods:

apply
map
applymap
replace







