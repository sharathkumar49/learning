

Python Multiprocessing Tutorial:


1. Introduction to Multiprocessing
Multiprocessing allows true parallel execution by spawning separate processes on multiple CPU cores. Unlike threading, which suffers from the Global Interpreter Lock (GIL), multiprocessing fully utilizes multiple CPU cores, making it ideal for CPU-bound tasks.



Key Differences Between Threading & Multiprocessing:

Feature	                            Threading (concurrent execution)	                 Multiprocessing (parallel execution)
------------------------------------------------------------------------------------------------------------------------------------------------------
Execution Model	         Multiple threads share memory space, affected by the GIL	     Each process runs independently, avoiding GIL restrictions
Ideal Use Cases	         IO-bound tasks (network requests, file operations)	             CPU-bound tasks (heavy computations, image processing)
Memory Usage	         Threads share memory, reducing overhead	                     Each process has its own memory space, increasing overhead
Performance Impact	     Limited by GIL, preventing full parallel execution	             True parallel execution by utilizing multiple CPU cores



Multiprocessing is preferred when each task requires intensive computation, such as:
Image or video processing
Scientific computing
Data analysis with large datasets




2. Basic Multiprocessing Example:
Synchronous Execution Without Multiprocessing:
import time

start = time.perf_counter()

def do_something():
    print('Sleeping for 1 second...')
    time.sleep(1)
    print('Done sleeping...')

do_something()
do_something()

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')
Each function call executes sequentially, taking 2 seconds total.



Parallel Execution Using multiprocessing:
import multiprocessing
import time

start = time.perf_counter()

def do_something():
    print('Sleeping for 1 second...')
    time.sleep(1)
    print('Done sleeping...')

p1 = multiprocessing.Process(target=do_something)
p2 = multiprocessing.Process(target=do_something)

p1.start()
p2.start()

p1.join()
p2.join()

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')


Key Improvements: 
‚úÖ Each process runs independently on separate CPU cores 
‚úÖ Total execution time reduces significantly 
‚úÖ Avoids GIL limitations, allowing full parallel execution




3. Passing Arguments to Multiprocessing
Using args to Pass Parameters:
import multiprocessing
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping for {seconds} second(s)...')
    time.sleep(seconds)
    print('Done sleeping...')

processes = []

for _ in range(10):
    p = multiprocessing.Process(target=do_something, args=[1.5])
    p.start()
    processes.append(p)

for process in processes:
    process.join()

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')


Concepts introduced: 
‚úÖ Dynamic process creation using a loop 
‚úÖ Passing arguments via args=[1.5], allowing flexible execution 
‚úÖ Processes run in parallel, significantly reducing execution time




4. Using the concurrent.futures Module
Using submit() for Parallel Execution:
import concurrent.futures
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping for {seconds} second(s)...')
    time.sleep(seconds)
    return f'Done Sleeping...{seconds}'

with concurrent.futures.ProcessPoolExecutor() as executor:
    f1 = executor.submit(do_something, 1)
    print(f1.result())

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')
Advantages: ‚úÖ Automates process management ‚úÖ Returns a Future object, allowing easy result retrieval




Using List Comprehension:
import concurrent.futures
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping for {seconds} second(s)...')
    time.sleep(seconds)
    return f'Done Sleeping...{seconds}'

with concurrent.futures.ProcessPoolExecutor() as executor:
    secs = [5, 4, 3, 2, 1]
    results = [executor.submit(do_something, sec) for sec in secs]

    for f in concurrent.futures.as_completed(results):
        print(f.result())

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')

‚úÖ Tasks complete in any order, but results print as each finishes.



Using map() for Ordered Execution:
import concurrent.futures
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping for {seconds} second(s)...')
    time.sleep(seconds)
    return f'Done Sleeping...{seconds}'

with concurrent.futures.ProcessPoolExecutor() as executor:
    secs = [5, 4, 3, 2, 1]
    results = executor.map(do_something, secs)

    for result in results:
        print(result)

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')

‚úÖ Ensures results print in the same order they were submitted.





5. Real-World Multiprocessing Example: Image Processing
Multiprocessing is ideal for processing large datasets efficiently.
import time
import concurrent.futures
from PIL import Image, ImageFilter

img_names = [
    'photo-1516117172878-fd2c41f4a759.jpg',
    'photo-1532009324734-20a7a5813719.jpg',
    # More images...
]

start = time.perf_counter()
size = (1200, 1200)

def process_image(img_name):
    img = Image.open(img_name)
    img = img.filter(ImageFilter.GaussianBlur(15))
    img.thumbnail(size)
    img.save(f'processed/{img_name}')
    print(f'{img_name} was processed...')

with concurrent.futures.ProcessPoolExecutor() as executor:
    executor.map(process_image, img_names)

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')

Key Benefits: 
‚úÖ Utilizes all available CPU cores 
‚úÖ Processes multiple images in parallel, reducing execution time




6. Multiprocessing Best Practices
‚úî Use Multiprocessing for CPU-heavy tasks (math, image processing, data analysis) 
‚úî Threading is better for IO-bound tasks (file operations, network requests) 
‚úî Avoid excessive processes, as creating too many increases overhead 
‚úî Use ProcessPoolExecutor for cleaner, more efficient multiprocessing 
‚úî Multiprocessing increases memory usage, since each process has its own memory space

---------------------------------------------------------------------------------------------------------------------------------------------------------------------

what do they mean 'overhead' here. They're referring it in both multithreading and multiprocessing?

Great question! Overhead refers to the extra computational cost or resource consumption that comes with managing threads or processes. It impacts performance and efficiency.

Overhead in Multithreading:
Context Switching: Since Python threads run concurrently (not truly in parallel), the system constantly switches between threads. This switching requires CPU time and memory.
Synchronization Costs: If multiple threads share resources, synchronization techniques (locks, semaphores) introduce additional delays.
Thread Management: The OS must track and schedule multiple threads, which consumes processing power.

üìù Key Takeaway: While multithreading is great for IO-bound tasks, excessive threads can slow execution due to increased context switching and synchronization overhead.



Overhead in Multiprocessing:
Memory Usage: Each process has its own separate memory space, unlike threads that share memory. More processes = higher memory consumption.
Process Creation & Communication: Spawning new processes takes longer than creating threads. Additionally, inter-process communication (IPC) is slower than thread communication.
Data Transfer Overhead: Since processes don‚Äôt share memory, passing data between them (via queues or pipes) adds processing costs.

üìù Key Takeaway: Multiprocessing achieves true parallel execution, but excessive processes can cause memory and communication overhead.


Comparing Overheads:

Feature	Multithreading Overhead	Multiprocessing Overhead:
-------------------------------------------------------------------------------------------
Memory Usage	      Lower (shared memory)	                   Higher (independent processes)
----------------------------------------------------------------------------------------------
Communication Cost	  Lower (shared variables)	               Higher (requires IPC like queues)
Context Switching	  Higher (frequent switching)	           Lower (independent execution)
Process Management	  Lightweight, quick to start	           Heavy, slow to start due to OS scheduling


Conclusion:
Use multithreading when managing many lightweight tasks that share memory.
Use multiprocessing when performing heavy CPU-bound tasks where parallel execution outweighs the overhead cost.





---------------------------------------------------------------------------------------------------------------------------------------------------------------------

Here are some additional multiprocessing concepts and advanced techniques that might be useful for your notes.


1. Process Synchronization:
When multiple processes modify shared resources (e.g., files, databases), synchronization mechanisms prevent race conditions:
Locks (multiprocessing.Lock()): Ensures only one process accesses a resource at a time.
Semaphores (multiprocessing.Semaphore()): Limits access to a resource to a fixed number of processes.
Condition Variables (multiprocessing.Condition()): Allows processes to wait until a certain condition is met.
Manager Objects (multiprocessing.Manager()): Enables safe sharing of objects across processes.

Example:
import multiprocessing
import time

lock = multiprocessing.Lock()

def critical_section(name):
    with lock:  # Ensures exclusive access
        print(f'{name} is executing')
        time.sleep(1)

processes = [multiprocessing.Process(target=critical_section, args=(f'Process {i}',)) for i in range(5)]
for p in processes:
    p.start()
for p in processes:
    p.join()
	
‚úÖ Ensures safe execution, preventing data corruption due to concurrent modifications.



2. Interprocess Communication (IPC)
Since multiprocessing creates separate memory spaces, data exchange between processes must happen via:
Queues (multiprocessing.Queue()): FIFO (First-In-First-Out) mechanism for passing data.
Pipes (multiprocessing.Pipe()): Direct communication between two processes.
Shared Memory (multiprocessing.Array() & multiprocessing.Value()): Direct access to memory variables across processes.

Example: Using Queue for data exchange
import multiprocessing

def worker(queue):
    queue.put("Processed Data")

if __name__ == "__main__":
    queue = multiprocessing.Queue()
    process = multiprocessing.Process(target=worker, args=(queue,))
    process.start()
    process.join()
    
    print(queue.get())  # Output: Processed Data
	
‚úÖ Processes communicate safely using queues without modifying shared memory.




3. Using Shared Memory for Faster Communication
Instead of using queues, processes can access the same memory space, reducing overhead.

Example: Using Value (shared memory object)

import multiprocessing

def increment(shared_counter):
    with shared_counter.get_lock():
        shared_counter.value += 1

if __name__ == "__main__":
    counter = multiprocessing.Value('i', 0)  # Shared integer
    processes = [multiprocessing.Process(target=increment, args=(counter,)) for _ in range(10)]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print("Final Counter:", counter.value)  # Expected: 10

‚úÖ Processes directly update shared memory, reducing interprocess communication overhead.




4. Multiprocessing with Worker Pools
Instead of manually handling processes, ProcessPoolExecutor simplifies execution.

Example:
import concurrent.futures
import time

def compute(x):
    time.sleep(1)
    return x ** 2

with concurrent.futures.ProcessPoolExecutor() as executor:
    results = executor.map(compute, range(10))

print(list(results))  # Output: Squared values of 0-9

‚úÖ Ideal for CPU-intensive parallel computation.



5. Multiprocessing Debugging & Profiling
Use multiprocessing.active_children(): Lists active processes.
Profile Execution with cProfile: Analyzes CPU time distribution in multiprocessing workflows.
Set multiprocessing.set_start_method('fork') (Linux/macOS) or spawn (Windows): Controls process creation method.

Example:
import multiprocessing

print("Active Processes:", multiprocessing.active_children())

‚úÖ Monitors and profiles running multiprocessing tasks efficiently.




6. Best Practices for Multiprocessing
‚úî Use worker pools (ProcessPoolExecutor) instead of manually creating processes. 
‚úî Optimize process count (multiprocessing.cpu_count()) to balance efficiency. 
‚úî Avoid excessive interprocess communication (use shared memory if needed). 
‚úî For simple tasks, multiprocessing may add overhead‚Äîuse threading instead. 
‚úî Be mindful of resource constraints (RAM, disk IO), especially in large-scale parallel processing.


---------------------------------------------------------------------------------------------------------------------------------------------------------------------

Python's multiprocessing module is designed to enable parallel execution of tasks by spawning multiple processes, taking advantage of multiple CPU cores, which leads to better performance compared to threading (which is limited by Python's Global Interpreter Lock - GIL).

1. Multiprocessing Overview
The multiprocessing module allows the creation of separate processes, each with its own memory space, unlike threads that share memory. Key advantages include:
True parallel execution of CPU-bound tasks.
Avoiding Python's GIL limitations.
Independent memory space for each process, reducing shared-memory conflicts.



2. multiprocessing.Process
The multiprocessing.Process class is fundamental to creating and managing child processes.

Usage
Each Process instance runs a target function in a separate process.

import multiprocessing

def worker_function(name):
    print(f"Hello from {name}")

if __name__ == "__main__":
    p = multiprocessing.Process(target=worker_function, args=("Process-1",))
    p.start()  # Starts the process
    p.join()   # Waits for process completion

Methods:
start(): Starts the process.
join(): Waits for the process to finish execution.
terminate(): Forcefully stops the process.
is_alive(): Checks if the process is still running.
pid: Returns the process ID.

Each process runs independently, meaning changes in one process's memory won‚Äôt affect another.




3. multiprocessing.Queue
The Queue class is used for inter-process communication. It provides thread-safe mechanisms for passing data between processes.

Usage:
import multiprocessing

def worker(queue):
    queue.put("Hello from the process!")

if __name__ == "__main__":
    q = multiprocessing.Queue()
    p = multiprocessing.Process(target=worker, args=(q,))
    p.start()
    p.join()

    print(q.get())  # Retrieves the data from the queue
	
Methods:
put(item): Adds an item to the queue.
get(): Retrieves an item from the queue.
empty(): Checks if the queue is empty.
full(): Checks if the queue is full.
qsize(): Returns an estimate of items in the queue.

Queues allow processes to share data safely without direct memory sharing.



4. multiprocessing.Event
The Event class is used for synchronization between processes. It helps processes to wait for specific signals.

Usage:
import multiprocessing
import time

def worker(event):
    print("Waiting for the event to be set...")
    event.wait()  # Blocks execution until event is set
    print("Event is set, proceeding!")

if __name__ == "__main__":
    e = multiprocessing.Event()
    p = multiprocessing.Process(target=worker, args=(e,))
    p.start()
    
    time.sleep(2)
    e.set()  # Unblocks the worker process
    p.join()
	
	
Methods:
set(): Sets the event flag, allowing waiting processes to proceed.
clear(): Clears the flag, causing wait() to block.
is_set(): Checks if the event flag is set.
wait(timeout=None): Blocks until the event is set or times out.

Events are useful for process synchronization, ensuring orderly execution.





5. How Multiprocessing Works Internally
Each process is created using the Process class and operates independently.
Inter-process communication (IPC) is done via Queue, Pipe, or SharedMemory.
Synchronization is managed with tools like Event, Lock, and Semaphore.
Processes consume CPU resources directly, avoiding GIL limitations.



Summary
Process: Creates independent processes.
Queue: Enables communication between processes.
Event: Provides synchronization mechanisms.


---------------------------------------------------------------------------------------------------------------------------------------------------------------------

Multiprocessing Event Set() and is_set():
-----------------------------------------

Multiprocessing.Event: set() and is_set()
The multiprocessing.Event class is used for synchronization between processes. It acts like a flag that processes can check to determine whether to proceed or wait.

Event Methods:
1. set(): Sets the event flag, signaling all waiting processes to continue execution.
2. is_set(): Returns True if the event flag is set, otherwise False.

Example Usage:

import multiprocessing
import time

def worker(event):
    print("Worker waiting for event to be set...")
    event.wait()  # Blocks execution until event is set
    print("Event is set! Proceeding with work.")

if __name__ == "__main__":
    e = multiprocessing.Event()
    
    p = multiprocessing.Process(target=worker, args=(e,))
    p.start()

    time.sleep(2)
    print("Setting event...")
    e.set()  # Unblocks worker process
    print("Event is set:", e.is_set())  # Check if event is set

    p.join()
	
	
Explanation:
The worker process starts and waits (event.wait()) until the event is set.
The main process sleeps for 2 seconds, then calls event.set(), allowing the worker to continue.
Calling event.is_set() confirms whether the event flag has been set.




Multiprocessing.Pool:
The multiprocessing.Pool class is used for managing multiple worker processes efficiently. It enables parallel execution of functions with multiple inputs.

Methods:
apply(func, args): Runs a function in one worker process (blocking).
apply_async(func, args): Runs a function asynchronously in a worker process.
map(func, iterable): Maps an iterable to worker processes.
map_async(func, iterable): Asynchronously maps an iterable to worker processes.
close(): Prevents new tasks from being submitted.
join(): Waits for worker processes to complete.

Example Usage:
import multiprocessing

def square(n):
    return n * n

if __name__ == "__main__":
    with multiprocessing.Pool(processes=4) as pool:
        numbers = [1, 2, 3, 4, 5]
        results = pool.map(square, numbers)
        print("Squared numbers:", results)
		
		
Explanation:
A pool of 4 worker processes is created.
The map() function distributes tasks among the workers.
Each process computes the square of a number in parallel.





Multiprocessing.Manager:
The multiprocessing.Manager provides shared objects such as lists and dictionaries among multiple processes.

Methods
dict(): Creates a shared dictionary.
list(): Creates a shared list.
Value(): Creates a shared variable.
Array(): Creates a shared array.

Example Usage:
import multiprocessing

def worker(shared_list):
    shared_list.append("Hello from process!")

if __name__ == "__main__":
    manager = multiprocessing.Manager()
    shared_list = manager.list()
    
    p = multiprocessing.Process(target=worker, args=(shared_list,))
    p.start()
    p.join()

    print("Shared List:", shared_list)



Explanation:
The Manager creates a shared list.
The worker process modifies the list, which remains accessible to the main process.






Multiprocessing.Lock:
The multiprocessing.Lock ensures that only one process accesses a shared resource at a time.

Methods
acquire(): Locks access to the shared resource.
release(): Unlocks access to the shared resource.

Example Usage:
import multiprocessing
import time

def worker(lock):
    lock.acquire()
    print("Process accessing critical section.")
    time.sleep(2)
    print("Process exiting critical section.")
    lock.release()

if __name__ == "__main__":
    lock = multiprocessing.Lock()
    
    p1 = multiprocessing.Process(target=worker, args=(lock,))
    p2 = multiprocessing.Process(target=worker, args=(lock,))
    
    p1.start()
    p2.start()
    
    p1.join()
    p2.join()
	
	
	
Explanation:
Both processes try to enter a critical section.
The Lock ensures only one process executes at a time.
The first process acquires the lock, works, then releases it for the next process.

Summary:
Event: Signals between processes (set() and is_set() for control).
Pool: Manages multiple worker processes efficiently.
Manager: Shares complex data structures across processes.
Lock: Prevents simultaneous access to critical sections.


---------------------------------------------------------------------------------------------------------------------------------------------------------------------

In Python's multiprocessing module, an Event is a simple synchronization mechanism that allows multiple processes to communicate. The set() and is_set() methods help control the event's state and synchronize processes efficiently.

How It Works:
1. Event objects start with a default state of False (unset).
2. set(): Changes the event's state to True, signaling all waiting processes to proceed.
3. clear(): Resets the event's state to False, making processes wait again.
4. is_set(): Checks whether the event is currently set (True) or not (False).


Example with Multiple Processes:
Let's see how set() and is_set() work with two processes waiting for a signal:

import multiprocessing
import time

def worker(event, name):
    print(f"{name} is waiting for the event to be set...")
    event.wait()  # Blocks until the event is set
    print(f"{name} received the signal! Proceeding...")

if __name__ == "__main__":
    event = multiprocessing.Event()  # Create an Event object

    # Create two processes that will wait for the event
    process1 = multiprocessing.Process(target=worker, args=(event, "Process 1"))
    process2 = multiprocessing.Process(target=worker, args=(event, "Process 2"))

    process1.start()
    process2.start()

    time.sleep(3)  # Simulating some delay
    print("Main process setting the event.")
    event.set()  # Signal all waiting processes

    process1.join()
    process2.join()
	
	
Explanation:
1. Both processes start and check for the event.
2. They block at event.wait() because the event is initially unset (False).
3. After 3 seconds, the main process calls event.set(), changing the event state to True.
4. All waiting processes immediately unblock and continue execution.

This method ensures coordination across multiple processes and prevents race conditions.



Explain the role of clear() in the event set:
The clear() method in multiprocessing.Event plays a crucial role in resetting the event back to an unset (False) state. This forces any processes that call wait() on the event to pause execution until the event is set again.

Key Behavior of clear()
When you call event.set(), the event state changes to True, allowing waiting processes to continue.
Calling event.clear() reverses this, making the event False again.
Any process that calls wait() after clear() will pause until set() is called again.

Example: Using clear() in Multiprocessing
Let's modify the previous example to include clear():


import multiprocessing
import time

def worker(event, name):
    while True:
        print(f"{name} is waiting for the event to be set...")
        event.wait()  # Blocks until the event is set
        print(f"{name} received the signal! Proceeding...")

        time.sleep(2)  # Simulating task execution
        print(f"{name} completed work. Clearing event.")
        event.clear()  # Reset the event

if __name__ == "__main__":
    event = multiprocessing.Event()

    process1 = multiprocessing.Process(target=worker, args=(event, "Process 1"))
    process2 = multiprocessing.Process(target=worker, args=(event, "Process 2"))

    process1.start()
    process2.start()

    time.sleep(3)
    print("Main process setting the event.")
    event.set()  # Allow both processes to proceed

    time.sleep(5)
    print("Main process setting the event again.")
    event.set()  # Allow processes to run again

    process1.join()
    process2.join()


	
How clear() Works in This Example:
1. Processes start and wait for the event (event.wait()).
2. Main process sets the event (event.set()), allowing both processes to proceed.
3. Each process completes its task and calls event.clear(), resetting the event.
4. Processes will again wait for the next event.set() signal from the main process.

This cycle ensures controlled execution‚Äîprocesses only proceed when explicitly signaled, making synchronization more efficient.


---------------------------------------------------------------------------------------------------------------------------------------------------------------------

Various methods in all the approaches:


Python's multiprocessing module offers a variety of methods across different classes to facilitate process creation, management, communication, and synchronization. Here‚Äôs a comprehensive breakdown of additional important methods:

1. Process-related Methods (multiprocessing.Process)
start() ‚Äì Begins the execution of the process.
run() ‚Äì The method executed within the process (normally overridden).
join(timeout=None) ‚Äì Waits for the process to complete, with an optional timeout.
terminate() ‚Äì Immediately stops the process.
is_alive() ‚Äì Checks if the process is still running.
pid ‚Äì Returns the process ID.
exitcode ‚Äì Retrieves the exit code of the process after it terminates.
daemon ‚Äì If set to True, the process will terminate when the main process ends.


2. Queue-related Methods (multiprocessing.Queue)
put(item, block=True, timeout=None) ‚Äì Adds an item to the queue, optionally blocking if full.
get(block=True, timeout=None) ‚Äì Retrieves an item from the queue.
empty() ‚Äì Returns True if the queue is empty.
full() ‚Äì Returns True if the queue is full.
qsize() ‚Äì Provides an estimated size of the queue (not always reliable due to multiprocessing constraints).


3. Pool-related Methods (multiprocessing.Pool)
apply(func, args) ‚Äì Runs a function in one worker process (blocking).
apply_async(func, args, callback=None) ‚Äì Runs a function asynchronously in a worker process.
map(func, iterable, chunksize=None) ‚Äì Distributes work among processes (blocking).
map_async(func, iterable, chunksize=None, callback=None) ‚Äì Asynchronously distributes work among processes.
starmap(func, iterable, chunksize=None) ‚Äì Similar to map(), but allows multiple arguments.
starmap_async(func, iterable, chunksize=None, callback=None) ‚Äì Asynchronous version of starmap().
close() ‚Äì Prevents new tasks from being submitted to the pool.
join() ‚Äì Waits for worker processes to finish.
terminate() ‚Äì Forcefully stops all worker processes.


4. Manager-related Methods (multiprocessing.Manager)
dict() ‚Äì Creates a shared dictionary.
list() ‚Äì Creates a shared list.
Value(typecode, value) ‚Äì Creates a shared variable.
Array(typecode, iterable) ‚Äì Creates a shared array.
Namespace() ‚Äì Creates an object with arbitrary attributes.


5. Lock-related Methods (multiprocessing.Lock)
acquire(block=True, timeout=None) ‚Äì Blocks the execution until the lock is acquired.
release() ‚Äì Unlocks the resource, allowing other processes to use it.


6. Event-related Methods (multiprocessing.Event)
set() ‚Äì Sets the event flag, allowing waiting processes to proceed.
clear() ‚Äì Clears the flag, causing wait() to block.
is_set() ‚Äì Checks if the event flag is set.
wait(timeout=None) ‚Äì Blocks until the event is set or times out.



7. Semaphore-related Methods (multiprocessing.Semaphore)
acquire(block=True, timeout=None) ‚Äì Decreases the semaphore counter, blocking if necessary.
release() ‚Äì Increases the semaphore counter.

Semaphores are useful for limiting the number of concurrent processes accessing a shared resource.



8. Shared Memory-related Methods (multiprocessing.shared_memory)
SharedMemory(name=None, create=False, size=0) ‚Äì Creates or attaches to an existing shared memory block.
close() ‚Äì Disconnects from shared memory.
unlink() ‚Äì Deletes the shared memory block.

Shared memory allows multiple processes to access the same data without serialization.

Summary
These methods provide fine-grained control over parallel execution, process communication, and resource synchronization.