

Python Multiprocessing Tutorial:


1. Introduction to Multiprocessing
Multiprocessing allows true parallel execution by spawning separate processes on multiple CPU cores. Unlike threading, which suffers from the Global Interpreter Lock (GIL), multiprocessing fully utilizes multiple CPU cores, making it ideal for CPU-bound tasks.



Key Differences Between Threading & Multiprocessing:

Feature	                            Threading (concurrent execution)	                 Multiprocessing (parallel execution)
------------------------------------------------------------------------------------------------------------------------------------------------------
Execution Model	         Multiple threads share memory space, affected by the GIL	     Each process runs independently, avoiding GIL restrictions
Ideal Use Cases	         IO-bound tasks (network requests, file operations)	             CPU-bound tasks (heavy computations, image processing)
Memory Usage	         Threads share memory, reducing overhead	                     Each process has its own memory space, increasing overhead
Performance Impact	     Limited by GIL, preventing full parallel execution	             True parallel execution by utilizing multiple CPU cores



Multiprocessing is preferred when each task requires intensive computation, such as:
Image or video processing
Scientific computing
Data analysis with large datasets




2. Basic Multiprocessing Example:
Synchronous Execution Without Multiprocessing:
import time

start = time.perf_counter()

def do_something():
    print('Sleeping for 1 second...')
    time.sleep(1)
    print('Done sleeping...')

do_something()
do_something()

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')
Each function call executes sequentially, taking 2 seconds total.



Parallel Execution Using multiprocessing:
import multiprocessing
import time

start = time.perf_counter()

def do_something():
    print('Sleeping for 1 second...')
    time.sleep(1)
    print('Done sleeping...')

p1 = multiprocessing.Process(target=do_something)
p2 = multiprocessing.Process(target=do_something)

p1.start()
p2.start()

p1.join()
p2.join()

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')


Key Improvements: 
‚úÖ Each process runs independently on separate CPU cores 
‚úÖ Total execution time reduces significantly 
‚úÖ Avoids GIL limitations, allowing full parallel execution




3. Passing Arguments to Multiprocessing
Using args to Pass Parameters:
import multiprocessing
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping for {seconds} second(s)...')
    time.sleep(seconds)
    print('Done sleeping...')

processes = []

for _ in range(10):
    p = multiprocessing.Process(target=do_something, args=[1.5])
    p.start()
    processes.append(p)

for process in processes:
    process.join()

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')


Concepts introduced: 
‚úÖ Dynamic process creation using a loop 
‚úÖ Passing arguments via args=[1.5], allowing flexible execution 
‚úÖ Processes run in parallel, significantly reducing execution time




4. Using the concurrent.futures Module
Using submit() for Parallel Execution:
import concurrent.futures
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping for {seconds} second(s)...')
    time.sleep(seconds)
    return f'Done Sleeping...{seconds}'

with concurrent.futures.ProcessPoolExecutor() as executor:
    f1 = executor.submit(do_something, 1)
    print(f1.result())

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')
Advantages: ‚úÖ Automates process management ‚úÖ Returns a Future object, allowing easy result retrieval




Using List Comprehension:
import concurrent.futures
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping for {seconds} second(s)...')
    time.sleep(seconds)
    return f'Done Sleeping...{seconds}'

with concurrent.futures.ProcessPoolExecutor() as executor:
    secs = [5, 4, 3, 2, 1]
    results = [executor.submit(do_something, sec) for sec in secs]

    for f in concurrent.futures.as_completed(results):
        print(f.result())

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')

‚úÖ Tasks complete in any order, but results print as each finishes.



Using map() for Ordered Execution:
import concurrent.futures
import time

start = time.perf_counter()

def do_something(seconds):
    print(f'Sleeping for {seconds} second(s)...')
    time.sleep(seconds)
    return f'Done Sleeping...{seconds}'

with concurrent.futures.ProcessPoolExecutor() as executor:
    secs = [5, 4, 3, 2, 1]
    results = executor.map(do_something, secs)

    for result in results:
        print(result)

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')

‚úÖ Ensures results print in the same order they were submitted.





5. Real-World Multiprocessing Example: Image Processing
Multiprocessing is ideal for processing large datasets efficiently.
import time
import concurrent.futures
from PIL import Image, ImageFilter

img_names = [
    'photo-1516117172878-fd2c41f4a759.jpg',
    'photo-1532009324734-20a7a5813719.jpg',
    # More images...
]

start = time.perf_counter()
size = (1200, 1200)

def process_image(img_name):
    img = Image.open(img_name)
    img = img.filter(ImageFilter.GaussianBlur(15))
    img.thumbnail(size)
    img.save(f'processed/{img_name}')
    print(f'{img_name} was processed...')

with concurrent.futures.ProcessPoolExecutor() as executor:
    executor.map(process_image, img_names)

finish = time.perf_counter()
print(f'Finished in {round(finish-start, 2)} seconds')

Key Benefits: 
‚úÖ Utilizes all available CPU cores 
‚úÖ Processes multiple images in parallel, reducing execution time




6. Multiprocessing Best Practices
‚úî Use Multiprocessing for CPU-heavy tasks (math, image processing, data analysis) 
‚úî Threading is better for IO-bound tasks (file operations, network requests) 
‚úî Avoid excessive processes, as creating too many increases overhead 
‚úî Use ProcessPoolExecutor for cleaner, more efficient multiprocessing 
‚úî Multiprocessing increases memory usage, since each process has its own memory space

---------------------------------------------------------------------------------------------------------------------------------------------------------------------

what do they mean 'overhead' here. They're referring it in both multithreading and multiprocessing?

Great question! Overhead refers to the extra computational cost or resource consumption that comes with managing threads or processes. It impacts performance and efficiency.

Overhead in Multithreading:
Context Switching: Since Python threads run concurrently (not truly in parallel), the system constantly switches between threads. This switching requires CPU time and memory.
Synchronization Costs: If multiple threads share resources, synchronization techniques (locks, semaphores) introduce additional delays.
Thread Management: The OS must track and schedule multiple threads, which consumes processing power.

üìù Key Takeaway: While multithreading is great for IO-bound tasks, excessive threads can slow execution due to increased context switching and synchronization overhead.



Overhead in Multiprocessing:
Memory Usage: Each process has its own separate memory space, unlike threads that share memory. More processes = higher memory consumption.
Process Creation & Communication: Spawning new processes takes longer than creating threads. Additionally, inter-process communication (IPC) is slower than thread communication.
Data Transfer Overhead: Since processes don‚Äôt share memory, passing data between them (via queues or pipes) adds processing costs.

üìù Key Takeaway: Multiprocessing achieves true parallel execution, but excessive processes can cause memory and communication overhead.


Comparing Overheads:

Feature	Multithreading Overhead	Multiprocessing Overhead:
-------------------------------------------------------------------------------------------
Memory Usage	      Lower (shared memory)	                   Higher (independent processes)
----------------------------------------------------------------------------------------------
Communication Cost	  Lower (shared variables)	               Higher (requires IPC like queues)
Context Switching	  Higher (frequent switching)	           Lower (independent execution)
Process Management	  Lightweight, quick to start	           Heavy, slow to start due to OS scheduling


Conclusion:
Use multithreading when managing many lightweight tasks that share memory.
Use multiprocessing when performing heavy CPU-bound tasks where parallel execution outweighs the overhead cost.





---------------------------------------------------------------------------------------------------------------------------------------------------------------------

Here are some additional multiprocessing concepts and advanced techniques that might be useful for your notes.


1. Process Synchronization:
When multiple processes modify shared resources (e.g., files, databases), synchronization mechanisms prevent race conditions:
Locks (multiprocessing.Lock()): Ensures only one process accesses a resource at a time.
Semaphores (multiprocessing.Semaphore()): Limits access to a resource to a fixed number of processes.
Condition Variables (multiprocessing.Condition()): Allows processes to wait until a certain condition is met.
Manager Objects (multiprocessing.Manager()): Enables safe sharing of objects across processes.

Example:
import multiprocessing
import time

lock = multiprocessing.Lock()

def critical_section(name):
    with lock:  # Ensures exclusive access
        print(f'{name} is executing')
        time.sleep(1)

processes = [multiprocessing.Process(target=critical_section, args=(f'Process {i}',)) for i in range(5)]
for p in processes:
    p.start()
for p in processes:
    p.join()
	
‚úÖ Ensures safe execution, preventing data corruption due to concurrent modifications.



2. Interprocess Communication (IPC)
Since multiprocessing creates separate memory spaces, data exchange between processes must happen via:
Queues (multiprocessing.Queue()): FIFO (First-In-First-Out) mechanism for passing data.
Pipes (multiprocessing.Pipe()): Direct communication between two processes.
Shared Memory (multiprocessing.Array() & multiprocessing.Value()): Direct access to memory variables across processes.

Example: Using Queue for data exchange
import multiprocessing

def worker(queue):
    queue.put("Processed Data")

if __name__ == "__main__":
    queue = multiprocessing.Queue()
    process = multiprocessing.Process(target=worker, args=(queue,))
    process.start()
    process.join()
    
    print(queue.get())  # Output: Processed Data
	
‚úÖ Processes communicate safely using queues without modifying shared memory.




3. Using Shared Memory for Faster Communication
Instead of using queues, processes can access the same memory space, reducing overhead.

Example: Using Value (shared memory object)

import multiprocessing

def increment(shared_counter):
    with shared_counter.get_lock():
        shared_counter.value += 1

if __name__ == "__main__":
    counter = multiprocessing.Value('i', 0)  # Shared integer
    processes = [multiprocessing.Process(target=increment, args=(counter,)) for _ in range(10)]
    
    for p in processes:
        p.start()
    for p in processes:
        p.join()
    
    print("Final Counter:", counter.value)  # Expected: 10

‚úÖ Processes directly update shared memory, reducing interprocess communication overhead.




4. Multiprocessing with Worker Pools
Instead of manually handling processes, ProcessPoolExecutor simplifies execution.

Example:
import concurrent.futures
import time

def compute(x):
    time.sleep(1)
    return x ** 2

with concurrent.futures.ProcessPoolExecutor() as executor:
    results = executor.map(compute, range(10))

print(list(results))  # Output: Squared values of 0-9

‚úÖ Ideal for CPU-intensive parallel computation.



5. Multiprocessing Debugging & Profiling
Use multiprocessing.active_children(): Lists active processes.
Profile Execution with cProfile: Analyzes CPU time distribution in multiprocessing workflows.
Set multiprocessing.set_start_method('fork') (Linux/macOS) or spawn (Windows): Controls process creation method.

Example:
import multiprocessing

print("Active Processes:", multiprocessing.active_children())

‚úÖ Monitors and profiles running multiprocessing tasks efficiently.




6. Best Practices for Multiprocessing
‚úî Use worker pools (ProcessPoolExecutor) instead of manually creating processes. 
‚úî Optimize process count (multiprocessing.cpu_count()) to balance efficiency. 
‚úî Avoid excessive interprocess communication (use shared memory if needed). 
‚úî For simple tasks, multiprocessing may add overhead‚Äîuse threading instead. 
‚úî Be mindful of resource constraints (RAM, disk IO), especially in large-scale parallel processing.